{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import keras\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w,img_h = 64, 64\n",
    "IMG_DIM = (img_w,img_h)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PATH = \"data/\"\n",
    "LABELS = [\"Fully Covered\", \"Not Covered\", \"Not a Face\", \"Partially Covered\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6621 files belonging to 4 classes.\n",
      "Using 5297 files for training.\n"
     ]
    }
   ],
   "source": [
    "# creating our training dataset\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=PATH,\n",
    "    image_size=(img_h,img_w),\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6621 files belonging to 4 classes.\n",
      "Using 1324 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# creating our validation training set\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=PATH,\n",
    "    image_size=IMG_DIM,\n",
    "    subset=\"validation\",\n",
    "    seed=234,\n",
    "    validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fully_covered', 'not_covered', 'not_face', 'partially_covered']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "\n",
    "class Model(keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_layer = keras.layers.InputLayer(input_shape=(64, 64, 3))\n",
    "        self.rescaling_layer = keras.layers.experimental.preprocessing.Rescaling(\n",
    "            1. / 255, input_shape=(img_h, img_w, 3))\n",
    "        self.layer_1 = keras.layers.Dense(64, activation='relu')\n",
    "        self.layer_2 = keras.layers.Dense(32, activation='relu')\n",
    "        self.layer_3 = keras.layers.Dense(16, activation='relu')\n",
    "        self.flatten_layer = keras.layers.Flatten()\n",
    "        self.output_layer = keras.layers.Dense(num_classes, activation='relu')\n",
    "\n",
    "    def call(self, ds):\n",
    "        ds = self.input_layer(ds)\n",
    "        ds = self.flatten_layer(ds)\n",
    "        ds = self.rescaling_layer(ds)\n",
    "        ds = self.layer_1(ds)\n",
    "        ds = self.layer_2(ds)\n",
    "        ds = self.layer_3(ds)\n",
    "        ds = self.flatten_layer(ds)\n",
    "        return self.output_layer(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 1.3964 - accuracy: 0.2250 - val_loss: 1.3863 - val_accuracy: 0.2168\n",
      "Epoch 2/5\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 1.3863 - accuracy: 0.2226 - val_loss: 1.3863 - val_accuracy: 0.2168\n",
      "Epoch 3/5\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 1.3863 - accuracy: 0.2226 - val_loss: 1.3863 - val_accuracy: 0.2168\n",
      "Epoch 4/5\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 1.3863 - accuracy: 0.2226 - val_loss: 1.3863 - val_accuracy: 0.2168\n",
      "Epoch 5/5\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 1.3863 - accuracy: 0.2226 - val_loss: 1.3863 - val_accuracy: 0.2168\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.3863 - accuracy: 0.2168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.386294960975647, 0.21676737070083618]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=5)\n",
    "\n",
    "model.evaluate(val_ds)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05ddc6ec5474a1f626a2be7b32cdbbeeb8d0940e4dc5109586420296a02a5144"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
